{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1fa66a-2fc5-47f9-9452-3330746f2eb6",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, TaskType, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65fca7a-8d5e-492f-b009-00dbcd9c1f28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "df = pd.read_json('./metro_qa_data.json') \n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "# 加载 tokenizer\n",
    "path = './IEITYuan/Yuan2-2B-Mars-hf'\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, add_eos_token=False, add_bos_token=False, eos_token='<eod>')\n",
    "tokenizer.add_tokens(['<sep>', '<pad>', '<mask>', '<predict>', '<FIM_SUFFIX>', '<FIM_PREFIX>', '<FIM_MIDDLE>', '<commit_before>', '<commit_msg>', '<commit_after>', '<jupyter_start>', '<jupyter_text>', '<jupyter_code>', '<jupyter_output>', '<empty_output>'], special_tokens=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 数据处理函数\n",
    "def process_func(example):\n",
    "    MAX_LENGTH = 384\n",
    "    question = tokenizer(f\"{example['question']}<sep>\")\n",
    "    answer = tokenizer(f\"{example['answer']}<eod>\")\n",
    "    \n",
    "    input_ids = question[\"input_ids\"] + answer[\"input_ids\"]\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    labels = [-100] * len(question[\"input_ids\"]) + answer[\"input_ids\"]  # 问题部分不计算loss\n",
    "\n",
    "    if len(input_ids) > MAX_LENGTH:  # 截断\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# 处理数据集\n",
    "tokenized_id = ds.map(process_func, remove_columns=ds.column_names)\n",
    "\n",
    "# 检查数据\n",
    "print(tokenizer.decode(tokenized_id[0]['input_ids']))\n",
    "print(tokenizer.decode([id for id in tokenized_id[0][\"labels\"] if id != -100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fcc211-918d-42c0-abb0-b847a846c9d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载模型并配置LoRA\n",
    "model = AutoModelForCausalLM.from_pretrained(path, device_map=\"auto\", torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "# LoRA 配置\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "# 构建PeftModel\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# 设置训练参数\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./output/Yuan2.0-2B_lora_bf16\",\n",
    "    per_device_train_batch_size=12,\n",
    "    gradient_accumulation_steps=1,\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True,\n",
    "    bf16=True\n",
    ")\n",
    "\n",
    "# 初始化Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_id,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a3a33-d7a5-4532-b59d-73b620b6709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成函数\n",
    "def generate(question):\n",
    "    prompt = f\"{question}<sep>\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "    outputs = model.generate(inputs, do_sample=False, max_length=256)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    print(output.split(\"<sep>\")[-1])\n",
    "\n",
    "# 测试生成\n",
    "test_question = \"如何查询地铁票价？\"\n",
    "generate(test_question)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "share": {
   "datetime": "2024-11-07T07:56:32.951Z",
   "image": {
    "name": "modelscope:1.19.2-pytorch2.3.0-gpu-py310-cu121-ubuntu22.04",
    "url": "dsw-registry-vpc.cn-hangzhou.cr.aliyuncs.com/pai/modelscope:1.19.2-pytorch2.3.0-gpu-py310-cu121-ubuntu22.04"
   },
   "instance": "dsw-5d3832778538bffa",
   "spec": {
    "id": "ecs.gn7i-c8g1.2xlarge",
    "type": "GPU"
   },
   "uid": "1232209962044675"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
